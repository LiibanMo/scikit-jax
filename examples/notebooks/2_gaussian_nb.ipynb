{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from jax import vmap, jit, tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 3: Dataset with Redundant Features\n",
      "   Feature1 Feature2 Feature3  Target\n",
      "0         A        W        L       0\n",
      "1         B        W        M       0\n",
      "2         C        W        N       1\n",
      "3         A        W        L       0\n",
      "4         B        W        M       1\n",
      "5         C        W        N       1\n",
      "6         A        W        L       2\n",
      "7         B        W        M       2\n",
      "8         C        W        N       2\n",
      "9         A        W        L       0\n",
      "10        B        W        M       0\n",
      "11        C        W        N       1\n",
      "12        A        W        L       0\n",
      "13        B        W        M       1\n",
      "14        C        W        N       1\n",
      "15        A        W        L       2\n",
      "16        B        W        M       2\n",
      "17        C        W        N       2\n",
      "18        A        W        L       0\n",
      "19        B        W        M       0\n"
     ]
    }
   ],
   "source": [
    "# Case 3: Dataset with Redundant Features\n",
    "data3 = {\n",
    "    'Feature1': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A',\n",
    "                 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B'],\n",
    "    'Feature2': ['W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W',\n",
    "                 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W'],  # Redundant feature\n",
    "    'Feature3': ['L', 'M', 'N', 'L', 'M', 'N', 'L', 'M', 'N', 'L',\n",
    "                 'M', 'N', 'L', 'M', 'N', 'L', 'M', 'N', 'L', 'M'],\n",
    "    'Target':   [0, 0, 1, 0, 1, 1, 2, 2, 2, 0,\n",
    "                 0, 1, 0, 1, 1, 2, 2, 2, 0, 0]\n",
    "}\n",
    "\n",
    "data = pd.DataFrame(data3)\n",
    "print(\"\\nCase 3: Dataset with Redundant Features\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Feature2  Feature3  Target\n",
      "0         0         0         0       0\n",
      "1         1         0         1       0\n",
      "2         2         0         2       1\n",
      "3         0         0         0       0\n",
      "4         1         0         1       1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for column in ['Feature1', 'Feature2', 'Feature3']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = jnp.asarray(data.drop(columns=['Target']).to_numpy(dtype=jnp.int32))\n",
    "y = jnp.asarray(data['Target'].to_numpy(dtype=jnp.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 3), (16,), (20, 3), (20,))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [0, 1, 2]\n",
      "Categories in each feature column: [Array([0, 1, 2], dtype=int32), Array([0], dtype=int32), Array([0, 1, 2], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "unique_classes = jnp.unique(y) \n",
    "unique_categories = list(map(jnp.unique, X.T))\n",
    "\n",
    "print(f'Classes: {unique_classes.tolist()}')\n",
    "print(f'Categories in each feature column: {unique_categories}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.375 , 0.3125, 0.3125], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def compute_priors(y):\n",
    "    return jnp.unique(y, return_counts=True, size=len(unique_classes))[1] / jnp.sum(jnp.unique(y, return_counts=True, size=len(unique_classes))[1])\n",
    "\n",
    "priors = compute_priors(y_train)\n",
    "priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_for_the_classes = [jnp.where(y_train == class_) for class_ in unique_classes]\n",
    "\n",
    "def restructure_matrix_into_blocks(X:jax.Array):\n",
    "    @jit\n",
    "    def restructure_by_indices(indices:jax.Array):\n",
    "        return X[indices]\n",
    "    return restructure_by_indices\n",
    "\n",
    "X_train_restructured = tree.flatten(tree.map(restructure_matrix_into_blocks(X_train), indices_for_the_classes))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_restructured[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Array([0.6666667 , 0.33333334], dtype=float32), Array([1.], dtype=float32), Array([0.6666667 , 0.33333334], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "def return_likelihoods_for_feature_column(column:jax.Array):\n",
    "    counts_of_feature_in_block = jnp.unique(column, return_counts=True)[1]\n",
    "    return counts_of_feature_in_block / jnp.sum(counts_of_feature_in_block)\n",
    "\n",
    "likelihoods_for_block_0 = list(map(return_likelihoods_for_feature_column, X_train_restructured[0].T))\n",
    "print(likelihoods_for_block_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Array([0.6666667 , 0.33333334], dtype=float32),\n",
       "  Array([1.], dtype=float32),\n",
       "  Array([0.6666667 , 0.33333334], dtype=float32)],\n",
       " [Array([0.2, 0.8], dtype=float32),\n",
       "  Array([1.], dtype=float32),\n",
       "  Array([0.2, 0.8], dtype=float32)],\n",
       " [Array([0.4, 0.2, 0.4], dtype=float32),\n",
       "  Array([1.], dtype=float32),\n",
       "  Array([0.4, 0.2, 0.4], dtype=float32)]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_likelihoods_for_blocks(block:jax.Array):\n",
    "    return list(map(return_likelihoods_for_feature_column, block.T))\n",
    "\n",
    "likelihoods = tree.map(compute_likelihoods_for_blocks, X_train_restructured)\n",
    "likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [1, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([1., 1., 1., 1.], dtype=float32), Array([0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = 0\n",
    "j = 1\n",
    "x_j = X_test.T[j]\n",
    "likelihoods[block][j][x_j], x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.25, dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_likelihood_for_block_i_feature_j_xij(x_ij:jax.Array, i:int, j:int):\n",
    "    return likelihoods[i][j][x_ij]\n",
    "\n",
    "def retrieve_likelihood_for_block_i_feature_j(feature_column:jax.Array, i:int, j:int):\n",
    "    return vmap(retrieve_likelihood_for_block_i_feature_j_xij, in_axes=(0, None, None))(feature_column, i, j)\n",
    "\n",
    "def retrieve_likelihood_for_block_i(X:jax.Array, i:int, j:int):\n",
    "    return vmap(retrieve_likelihood_for_block_i_feature_j, in_axes=(0, None, None))(X, i, j)\n",
    "\n",
    "block_of_likelihoods = [[] for _ in range(len(unique_classes))]\n",
    "posteriors_array = []\n",
    "for i in range(unique_classes.shape[0]):\n",
    "    for j in range(X_test.shape[1]):\n",
    "        v_array = retrieve_likelihood_for_block_i_feature_j(X_test.T[j], i, j)\n",
    "        block_of_likelihoods[i].append(v_array)\n",
    "    posteriors = jnp.prod(jnp.vstack(block_of_likelihoods[i]), axis=0)*priors[i]\n",
    "    posteriors_array.append(posteriors)\n",
    "\n",
    "y_pred = jnp.vstack(posteriors_array).argmin(axis=0)\n",
    "jnp.where(y_pred == y_test, 1, 0).mean()\n",
    "#jnp.prod(jnp.vstack(block_of_likelihoods[0]), axis=0)*priors[0], block_of_likelihoods[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.5, dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model_sk = MultinomialNB()\n",
    "model_sk_fitted = model_sk.fit(X_train, y_train)\n",
    "y_pred_sk = model_sk_fitted.predict(X_test)\n",
    "jnp.where(y_pred_sk == y_test, 1, 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([2, 1, 2], dtype=int32),\n",
       " Array([[1, 0, 1],\n",
       "        [1, 0, 1],\n",
       "        [0, 0, 0],\n",
       "        [1, 0, 1]], dtype=int32))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultinomialNaiveBayes():\n",
    "    def fit(self, X:jax.Array, y:jax.Array):\n",
    "        # Computing priors\n",
    "        self.priors = compute_priors(y)\n",
    "\n",
    "        # Computing likelihoods\n",
    "        self.unique_classes = jnp.unique(y)\n",
    "        self.num_classes = len(self.unique_classes)\n",
    "\n",
    "        indices_for_the_classes = [jnp.where(y == class_) for class_ in self.unique_classes]\n",
    "\n",
    "        self.X_restructured = tree.flatten(tree.map(restructure_matrix_into_blocks(X), indices_for_the_classes))[0]\n",
    "        \n",
    "        self.blocks_of_likelihoods = tree.map(compute_likelihoods_for_blocks, self.X_restructured)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X:jax.Array):\n",
    "        self.log_posteriors = jnp.zeros(shape=(X.shape[1], self.num_classes))\n",
    "        for i in range(self.unique_classes.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                array_of_prior_and_likelihoods = jnp.hstack((priors[i], retrieve_likelihood_for_block_i_feature_j(X.T[j], i, j)))\n",
    "                log_posterior = jnp.sum(jnp.log(array_of_prior_and_likelihoods))\n",
    "                self.log_posteriors = self.log_posteriors.at[j, i].set(log_posterior)\n",
    "\n",
    "        return self.log_posteriors.argmin(axis=1)\n",
    "    \n",
    "model = MultinomialNaiveBayes()\n",
    "model_fitted = model.fit(X_train, y_train)\n",
    "model_fitted.predict(X_test), X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
